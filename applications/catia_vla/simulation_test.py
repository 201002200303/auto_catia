
import os
import sys
import json
import time
import random
import asyncio
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
_project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(_project_root))

try:
    from function_hubs.catia_tools import (
        detect_ui_elements,
        capture_screen,
        click_element,
        activate_catia_window
    )
except ImportError:
    # å°è¯•ç›´æ¥ä»æ¨¡å—å¯¼å…¥ï¼ˆå¦‚æœä¸Šé¢çš„å¯¼å…¥å¤±è´¥ï¼‰
    import function_hubs.catia_tools as catia_tools_module
    detect_ui_elements = getattr(catia_tools_module, 'detect_ui_elements', None)
    capture_screen = getattr(catia_tools_module, 'capture_screen', None)
    click_element = getattr(catia_tools_module, 'click_element', None)
    activate_catia_window = getattr(catia_tools_module, 'activate_catia_window', None)

async def run_tool(func, **kwargs):
    """è¾…åŠ©å‡½æ•°ï¼šè¿è¡Œå·¥å…·ï¼ˆè‡ªåŠ¨å¤„ç†åŒæ­¥/å¼‚æ­¥ï¼‰"""
    if asyncio.iscoroutinefunction(func):
        return await func(**kwargs)
    return func(**kwargs)

def simulate_llm_decision(detection_json):
    """
    æ¨¡æ‹Ÿå¤§æ¨¡å‹å†³ç­–è¿‡ç¨‹ï¼š
    1. æ¥æ”¶æ£€æµ‹åˆ°çš„ UI å…ƒç´ åˆ—è¡¨
    2. è§„åˆ’ç‚¹å‡»é¡ºåº
    3. è¿”å›å†³ç­–ç»“æœï¼ˆJSONï¼‰
    """
    print("\n" + "="*40)
    print("ğŸ¤– [æ¨¡æ‹Ÿ LLM] æ­£åœ¨æ€è€ƒ...")
    print("="*40)
    
    try:
        detections = json.loads(detection_json)
    except json.JSONDecodeError:
        return json.dumps({
            "thought": "è§£ææ£€æµ‹ç»“æœå¤±è´¥ã€‚",
            "action": "wait",
            "target": None
        }, ensure_ascii=False)
    
    if not detections or isinstance(detections, dict) and "error" in detections:
        return json.dumps({
            "thought": "å±å¹•ä¸Šæ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•å¯ç”¨çš„ UI å…ƒç´ ã€‚",
            "action": "wait",
            "target": None
        }, ensure_ascii=False)
    
    # æ¨¡æ‹Ÿï¼šLLM å†³å®šç‚¹å‡»ç½®ä¿¡åº¦æœ€é«˜çš„é‚£ä¸ªå…ƒç´ 
    # æˆ–è€…éšæœºé€‰æ‹©ä¸€ä¸ª
    # è¿™é‡Œæˆ‘ä»¬é€‰æ‹©ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„å…ƒç´ ä½œä¸ºæ¼”ç¤º
    target = detections[0]
    
    # æ„é€ æ¨¡æ‹Ÿçš„ LLM è¾“å‡º
    llm_response = {
        "thought": f"æˆ‘çœ‹åˆ°äº† {len(detections)} ä¸ªå›¾æ ‡ã€‚æ ¹æ®ä»»åŠ¡è§„åˆ’ï¼Œæˆ‘éœ€è¦å…ˆç‚¹å‡» '{target['label']}'ã€‚",
        "plan": [
            f"ç‚¹å‡» {target['label']}",
            "ç­‰å¾…èœå•å¼¹å‡º",
            "é€‰æ‹©ä¸‹ä¸€æ­¥æ“ä½œ"
        ],
        "current_action": {
            "type": "click",
            "target_label": target['label'],
            "bbox": target['bbox'],
            "confidence": target['confidence']
        }
    }
    
    return json.dumps(llm_response, ensure_ascii=False, indent=2)

async def main():
    print("ğŸš€ å¼€å§‹æ¨¡æ‹Ÿ 'æ„ŸçŸ¥-å†³ç­–-æ‰§è¡Œ' é—­ç¯æµ‹è¯•")
    print("-" * 50)

    # 1. å°è¯•æ¿€æ´»çª—å£ï¼ˆå¯é€‰ï¼‰
    print("\nStep 1: å°è¯•æ¿€æ´» CATIA çª—å£...")
    activate_res = await run_tool(activate_catia_window)
    print(f"æ¿€æ´»ç»“æœ: {activate_res}")
    
    # 2. æˆªå›¾
    print("\nStep 2: æˆªå–å±å¹•...")
    # æ— è®ºæ˜¯å¦æ¿€æ´»æˆåŠŸï¼Œéƒ½å°è¯•æˆªå›¾
    screenshot_res_json = await run_tool(capture_screen)
    try:
        screenshot_res = json.loads(screenshot_res_json)
    except:
        print(f"âŒ æˆªå›¾ç»“æœè§£æå¤±è´¥: {screenshot_res_json}")
        return
    
    image_path = None
    if isinstance(screenshot_res, dict) and screenshot_res.get("success"):
        image_path = screenshot_res.get("file_path")
        print(f"âœ… æˆªå›¾æˆåŠŸ: {image_path}")
    else:
        print(f"âŒ æˆªå›¾å¤±è´¥: {screenshot_res}")
        # å¦‚æœæˆªå›¾å¤±è´¥ï¼Œä¹Ÿæ— æ³•ç»§ç»­
        return

    # 3. è§†è§‰è¯†åˆ«
    print("\nStep 3: è¯†åˆ«ç•Œé¢å…ƒç´ ...")
    detection_json = await run_tool(detect_ui_elements, image_path=image_path)
    detections = json.loads(detection_json)
    
    # å¦‚æœæ£€æµ‹ç»“æœä¸ºç©ºæˆ–æœ‰é”™è¯¯ï¼Œåˆ‡æ¢åˆ°æµ‹è¯•å›¾ç‰‡
    if not detections or (isinstance(detections, dict) and "error" in detections):
        print("âš ï¸  å½“å‰å±å¹•æœªæ£€æµ‹åˆ° CATIA å…ƒç´  (å¯èƒ½æ˜¯å› ä¸ºæœªæ‰“å¼€ CATIA)")
        print("ğŸ”„ åˆ‡æ¢åˆ°æµ‹è¯•å›¾ç‰‡è¿›è¡Œæ¨¡æ‹Ÿæ¼”ç¤º...")
        test_image = str(Path(__file__).parent / "perception" / "figures" / "11.jpg")
        if os.path.exists(test_image):
            print(f"è¯»å–æµ‹è¯•å›¾ç‰‡: {test_image}")
            detection_json = await run_tool(detect_ui_elements, image_path=test_image)
            image_path = test_image # æ›´æ–°å›¾ç‰‡è·¯å¾„
        else:
            print("âŒ æµ‹è¯•å›¾ç‰‡ä¹Ÿä¸å­˜åœ¨ï¼Œæ— æ³•ç»§ç»­æ¼”ç¤ºã€‚")
            return

    print(f"æ£€æµ‹ç»“æœ: {detection_json[:500]}..." + ("" if len(detection_json)<500 else "\n(æˆªæ–­å±•ç¤º)"))

    # 4. æ¨¡æ‹Ÿå¤§æ¨¡å‹å†³ç­–
    print("\nStep 4: å‘é€ç»™å¤§æ¨¡å‹è¿›è¡Œè§„åˆ’...")
    llm_output_json = simulate_llm_decision(detection_json)
    print(f"\nğŸ“œ [LLM è¾“å‡º]:\n{llm_output_json}")
    
    llm_output = json.loads(llm_output_json)
    
    if llm_output.get("action") == "wait":
        print("LLM å†³å®šç­‰å¾…ï¼Œæµç¨‹ç»“æŸã€‚")
        return

    # 5. è§£æå†³ç­–å¹¶æ‰§è¡Œ
    action = llm_output["current_action"]
    print(f"\nStep 5: æ‰§è¡ŒåŠ¨ä½œ -> ç‚¹å‡» {action['target_label']}")
    
    bbox = action["bbox"] # [x1, y1, x2, y2]
    
    x1, y1, x2, y2 = bbox
    center_x = int((x1 + x2) / 2)
    center_y = int((y1 + y2) / 2)
    
    print(f"ç›®æ ‡åæ ‡ (BBox): {bbox}")
    print(f"è®¡ç®—ä¸­å¿ƒç‚¹: ({center_x}, {center_y})")
    
    if "figures" in image_path:
        print("\nâš ï¸  è­¦å‘Š: æ­£åœ¨ä½¿ç”¨é™æ€æµ‹è¯•å›¾ç‰‡è¿›è¡Œæ¼”ç¤ºã€‚")
        print("    ç‚¹å‡»æ“ä½œå°†å‘é€åˆ°å±å¹•çš„ ({}, {}) ä½ç½®ã€‚".format(center_x, center_y))
        print("    è¿™å¯èƒ½ä¸ä¼šç‚¹å‡»åˆ°çœŸå®çš„å›¾æ ‡ï¼Œä»…ç”¨äºæµ‹è¯•ç‚¹å‡»åŠŸèƒ½æ˜¯å¦æ­£å¸¸è¿è¡Œã€‚")
    
    # æ‰§è¡Œç‚¹å‡»
    click_res_json = await run_tool(click_element, x=center_x, y=center_y)
    print(f"ç‚¹å‡»ç»“æœ: {click_res_json}")

if __name__ == "__main__":
    asyncio.run(main())
